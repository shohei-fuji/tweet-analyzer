{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tweepy\n",
    "import csv\n",
    "\n",
    "consumer_key = \"**************************\"\n",
    "consumer_secret = \"**************************\"\n",
    "access_key = \"**************************\"\n",
    "access_secret = \"**************************\"\n",
    "\n",
    "auth = tweepy.OAuthHandler(consumer_key, consumer_secret)\n",
    "auth.set_access_token(access_key, access_secret)\n",
    "api = tweepy.API(auth)\n",
    "\n",
    "# ツイート取得\n",
    "tweet_data = []\n",
    "\n",
    "for tweet in tweepy.Cursor(api.user_timeline,screen_name = \"@takapon_jp\",exclude_replies = True).items():\n",
    "    tweet_data.append([tweet.id,tweet.created_at,tweet.text.replace('\\n','')])\n",
    "\n",
    "# csv出力\n",
    "with open('./6050_stock_price_prediction_data/tweets_horie.csv', 'w',newline='',encoding='utf-8') as f:\n",
    "    writer = csv.writer(f, lineterminator='\\n')\n",
    "    writer.writerow([\"id\",\"text\",\"created_at\"])\n",
    "    writer.writerows(tweet_data)\n",
    "\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy  as np\n",
    "import MeCab\n",
    "\n",
    "df_tweets = pd.read_csv('./6050_stock_price_prediction_data/tweets_horie.csv', names=['id', 'date', 'text'], index_col='date')\n",
    "df_tweets = df_tweets[['text']].sort_index(ascending=True)\n",
    "\n",
    "# 辞書のデータフレームを作成．パスは適宜設定してください．\n",
    "pn_df = pd.read_csv('./6050_stock_price_prediction_data/pn_ja.csv', encoding='utf-8', names=('Word','Reading','POS', 'PN'))\n",
    "# 各列の分割\n",
    "word_list = list(pn_df['Word'])\n",
    "pn_list   = list(pn_df['PN'])\n",
    "pn_dict   = dict(zip(word_list, pn_list))\n",
    "\n",
    "# MeCabインスタンスの作成．引数を無指定にするとIPA辞書になります．\n",
    "m = MeCab.Tagger('')\n",
    "\n",
    "#NANを排除\n",
    "df_tweets = df_tweets.dropna()\n",
    "\n",
    "# テキストを形態素解析し辞書のリストを返す関数\n",
    "def get_diclist(text):\n",
    "    parsed = m.parse(text)      # 形態素解析結果（改行を含む文字列として得られる）\n",
    "    lines = parsed.split('\\n')  # 解析結果を1行（1語）ごとに分けてリストにする\n",
    "    lines = lines[0:-2]         # 後ろ2行は不要なので削除\n",
    "    diclist = []\n",
    "    for word in lines:\n",
    "        l = re.split('\\t|,',word)  # 各行はタブとカンマで区切られてるので\n",
    "        d = {'Surface':l[0], 'POS1':l[1], 'POS2':l[2], 'BaseForm':l[7]}\n",
    "        diclist.append(d)\n",
    "    return(diclist)\n",
    "\n",
    "# 形態素解析結果の単語ごとのdictデータにPN値を追加する関数\n",
    "def add_pnvalue(diclist_old, pn_dict):\n",
    "    diclist_new = []\n",
    "    for word in diclist_old:\n",
    "        base = word['BaseForm']        # 個々の辞書から基本形を取得\n",
    "        if base in pn_dict:\n",
    "            pn = float(pn_dict[base]) \n",
    "        else:\n",
    "            pn = 'notfound'            # その語がPN Tableになかった場合\n",
    "        word['PN'] = pn\n",
    "        diclist_new.append(word)\n",
    "    return(diclist_new)\n",
    "\n",
    "# 各ツイートのPN平均値を求める\n",
    "def get_mean(dictlist):\n",
    "    pn_list = []\n",
    "    for word in dictlist:\n",
    "        pn = word['PN']\n",
    "        if pn!='notfound':\n",
    "            pn_list.append(pn)\n",
    "    if len(pn_list)>0:\n",
    "        pnmean = np.mean(pn_list)\n",
    "    else:\n",
    "        pnmean=0\n",
    "    return pnmean\n",
    "\n",
    "means_list = []\n",
    "for tweet in df_tweets['text']:\n",
    "    dl_old = get_diclist(tweet)\n",
    "    dl_new = add_pnvalue(dl_old, pn_dict)\n",
    "    pnmean = get_mean(dl_new)\n",
    "    means_list.append(pnmean)\n",
    "means_list = np.copy(means_list)\n",
    "x_std = (means_list - means_list.mean()) / means_list.std()\n",
    "df_tweets['pn'] = x_std\n",
    "df_tweets = df_tweets.drop('text', axis=0)\n",
    "df_tweets.index = pd.to_datetime(df_tweets.index)\n",
    "df_tweets =  df_tweets.resample('D', how='mean')\n",
    "x = df_tweets.index\n",
    "y = df_tweets.pn\n",
    "plt.plot(x,y)\n",
    "plt.grid(True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
